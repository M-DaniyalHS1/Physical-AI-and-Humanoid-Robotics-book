"use strict";(globalThis.webpackChunkai_textbook_frontend=globalThis.webpackChunkai_textbook_frontend||[]).push([[602],{759(n,e,t){t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"ai/translation","title":"AI Translation","description":"This section covers AI-powered translation capabilities for Physical AI and Humanoid Robotics applications, with a focus on supporting the local language (Urdu) for Panaversity users. Translation enables broader access to educational content and enhances human-robot interaction in multilingual environments.","source":"@site/docs/ai/translation.md","sourceDirName":"ai","slug":"/ai/translation","permalink":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ai/translation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ai/translation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"AI Translation"},"sidebar":"tutorialSidebar","previous":{"title":"AI Personalization","permalink":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ai/personalization"}}');var s=t(4848),r=t(8453);const i={sidebar_position:3,title:"AI Translation"},l="AI Translation for Physical AI & Humanoid Robotics",o={},c=[{value:"Translation Architecture for Robotics",id:"translation-architecture-for-robotics",level:2},{value:"Overview of AI Translation in Robotics",id:"overview-of-ai-translation-in-robotics",level:3},{value:"Urdu Translation Implementation",id:"urdu-translation-implementation",level:2},{value:"Urdu Language Specifics",id:"urdu-language-specifics",level:3},{value:"Translation Cache and Performance",id:"translation-cache-and-performance",level:2},{value:"Optimized Translation Caching",id:"optimized-translation-caching",level:3},{value:"Content Translation for Educational Materials",id:"content-translation-for-educational-materials",level:2},{value:"Translating Textbook Content",id:"translating-textbook-content",level:3},{value:"Real-Time Translation for Chatbots",id:"real-time-translation-for-chatbots",level:2},{value:"Integration with AI Chatbot for Urdu Support",id:"integration-with-ai-chatbot-for-urdu-support",level:3},{value:"Translation Quality and Evaluation",id:"translation-quality-and-evaluation",level:2},{value:"Quality Assessment Framework",id:"quality-assessment-framework",level:3},{value:"ROS 2 Integration for Translation Services",id:"ros-2-integration-for-translation-services",level:2},{value:"Translation Service Node",id:"translation-service-node",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Async Translation Processing",id:"async-translation-processing",level:3}];function u(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"ai-translation-for-physical-ai--humanoid-robotics",children:"AI Translation for Physical AI & Humanoid Robotics"})}),"\n",(0,s.jsx)(e.p,{children:"This section covers AI-powered translation capabilities for Physical AI and Humanoid Robotics applications, with a focus on supporting the local language (Urdu) for Panaversity users. Translation enables broader access to educational content and enhances human-robot interaction in multilingual environments."}),"\n",(0,s.jsx)(e.h2,{id:"translation-architecture-for-robotics",children:"Translation Architecture for Robotics"}),"\n",(0,s.jsx)(e.h3,{id:"overview-of-ai-translation-in-robotics",children:"Overview of AI Translation in Robotics"}),"\n",(0,s.jsx)(e.p,{children:"AI translation in robotics involves:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Real-time translation of user commands and robot responses"}),"\n",(0,s.jsx)(e.li,{children:"Translation of educational content for different languages"}),"\n",(0,s.jsx)(e.li,{children:"Multimodal translation (text, speech, and gesture)"}),"\n",(0,s.jsx)(e.li,{children:"Context-aware translation considering robotics domain terminology"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from typing import Dict, List, Optional, Tuple\nimport asyncio\nimport logging\n\nclass TranslationManager:\n    def __init__(self):\n        self.translation_cache = {}\n        self.supported_languages = {\n            'en': 'English',\n            'ur': 'Urdu',\n            'hi': 'Hindi',\n            'es': 'Spanish'\n        }\n        self.translation_engine = self._initialize_translation_engine()\n\n    def _initialize_translation_engine(self):\n        \"\"\"Initialize the translation engine\"\"\"\n        # This would typically initialize an actual translation model\n        # For example, using Hugging Face transformers, OpenAI, etc.\n        return TranslationEngine()\n\n    def translate_text(self,\n                      text: str,\n                      source_lang: str = 'en',\n                      target_lang: str = 'ur',\n                      domain: str = 'robotics') -> str:\n        \"\"\"Translate text with domain-specific terminology\"\"\"\n        cache_key = f\"{text}_{source_lang}_{target_lang}_{domain}\"\n\n        # Check cache first\n        if cache_key in self.translation_cache:\n            return self.translation_cache[cache_key]\n\n        # Perform translation\n        translated_text = self.translation_engine.translate(\n            text=text,\n            source_lang=source_lang,\n            target_lang=target_lang,\n            domain=domain\n        )\n\n        # Store in cache\n        self.translation_cache[cache_key] = translated_text\n\n        return translated_text\n"})}),"\n",(0,s.jsx)(e.h2,{id:"urdu-translation-implementation",children:"Urdu Translation Implementation"}),"\n",(0,s.jsx)(e.h3,{id:"urdu-language-specifics",children:"Urdu Language Specifics"}),"\n",(0,s.jsx)(e.p,{children:"Urdu translation presents unique challenges and opportunities:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Naskh script"}),": Right-to-left writing system"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cultural context"}),": Different cultural concepts and expressions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Technical terminology"}),": Need for appropriate robotics/technology terms"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Formality levels"}),": Different registers for various contexts"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import unicodedata\nfrom transformers import MarianMTModel, MarianTokenizer\nimport torch\n\nclass UrduTranslationEngine:\n    def __init__(self):\n        self.models = {}\n        self.tokenizers = {}\n        self.domain_specialized_terms = self._load_domain_terms()\n\n        # Initialize Urdu translation models\n        self._load_urdu_models()\n\n    def _load_domain_terms(self) -> Dict[str, Dict[str, str]]:\n        \"\"\"Load domain-specific terminology for robotics\"\"\"\n        return {\n            'robotics': {\n                'robot': '\u0631\u0648\u0628\u0648\u0679',\n                'navigation': '\u06c1\u062f\u0627\u06cc\u062a',\n                'manipulation': '\u06c1\u0627\u062a\u06be',\n                'sensor': '\u0633\u06cc\u0646\u0633\u0631',\n                'actuator': '\u0627\u06cc\u06a9\u0686\u0648 \u0627\u06cc\u0679\u0631',\n                'algorithm': '\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645',\n                'perception': '\u0627\u062d\u0633\u0627\u0633',\n                'planning': ' \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc',\n                'control': '\u06a9\u0646\u0679\u0631\u0648\u0644',\n                'locomotion': '\u0686\u0644\u0646\u06d2 \u06a9\u06cc \u0635\u0644\u0627\u062d\u06cc\u062a',\n                'articulation': '\u0645 joint',\n                'gripper': '\u06af\u0631\u067e\u0631',\n                'end effector': '\u0622\u062e\u0631\u06cc \u06a9\u0627\u0631\u06a9\u0646',\n                'kinematics': '\u06a9\u0646\u064a\u0645\u0627\u062a\u06a9\u0633',\n                'dynamics': '\u0688\u0627\u0626\u0646\u0627\u0645\u06a9\u0633',\n                'trajectory': '\u0631\u062e',\n                'waypoint': '\u0631\u0627\u06c1 \u06a9\u0627 \u067e\u062a\u06be\u0631',\n                'pose': '\u067e\u0648\u0632',\n                'orientation': '\u0633\u0645\u062a',\n                'position': '\u0645\u0642\u0627\u0645',\n                'velocity': '\u0631\u0641\u0639\u062a',\n                'acceleration': '\u062a\u06cc\u0632\u06cc',\n                'force': '\u0642\u0648\u062a',\n                'torque': '\u0679\u0648\u0631\u06a9',\n                'feedback': '\u0631\u062f\u0639\u0645\u0644',\n                'autonomous': '\u062e\u0648\u062f\u06a9\u0627\u0631',\n                'teleoperation': '\u062f\u0648\u0631 \u06a9\u0627\u0631\u06cc',\n                'haptic': '\u06c1\u06cc\u067e\u0679\u06a9',\n                'tactile': '\u0686\u06be\u0648\u0646\u06d2 \u0648\u0627\u0644\u0627',\n                'vision': '\u0648\u0698\u0646',\n                'lidar': '\u0644\u06cc\u0632\u0631 \u0633\u06cc\u0646\u0633\u0631',\n                'imu': '\u0627\u0646\u0631\u062c\u06cc \u0645\u06cc\u0679\u0631',\n                'gps': '\u062c\u06cc \u067e\u06cc \u0627\u06cc\u0633',\n                'mapping': '\u0646\u0642\u0634\u06c1 \u06a9\u0627\u0631\u06cc',\n                'slam': 'SLAM',\n                'localization': '\u0645\u0642\u0627\u0645 \u06a9\u0627\u0631\u06cc',\n                'path planning': '\u0631\u0627\u06c1 \u06a9\u06cc \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc'\n            }\n        }\n\n    def _load_urdu_models(self):\n        \"\"\"Load translation models for Urdu\"\"\"\n        # Note: In practice, you would load actual models\n        # These are placeholder model names\n        try:\n            # Load English to Urdu model\n            self.models['en_ur'] = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ur')\n            self.tokenizers['en_ur'] = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ur')\n\n            # Load Urdu to English model\n            self.models['ur_en'] = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ur-en')\n            self.tokenizers['ur_en'] = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ur-en')\n\n        except Exception as e:\n            logging.warning(f\"Could not load translation models: {e}\")\n            # Fallback to a simpler implementation\n            self.models['en_ur'] = None\n            self.tokenizers['en_ur'] = None\n\n    def translate_urdu(self, text: str, source_lang: str = 'en') -> str:\n        \"\"\"Translate text to/from Urdu with domain-specific terms\"\"\"\n        target_lang = 'ur' if source_lang == 'en' else 'en'\n        model_key = f\"{source_lang}_{target_lang}\"\n\n        if model_key in self.models and self.models[model_key]:\n            return self._translate_with_model(text, source_lang, target_lang)\n        else:\n            # Fallback translation\n            return self._fallback_translation(text, source_lang)\n\n    def _translate_with_model(self, text: str, source_lang: str, target_lang: str) -> str:\n        \"\"\"Translate using pre-trained models\"\"\"\n        model_key = f\"{source_lang}_{target_lang}\"\n        tokenizer = self.tokenizers[model_key]\n        model = self.models[model_key]\n\n        # Tokenize input\n        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n\n        # Generate translation\n        with torch.no_grad():\n            outputs = model.generate(**inputs)\n\n        # Decode output\n        translated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        return translated\n\n    def _fallback_translation(self, text: str, source_lang: str) -> str:\n        \"\"\"Fallback translation method\"\"\"\n        # For demo purposes, return the same text with a note\n        return f\"[TRANSLATION NOT AVAILABLE] {text}\"\n"})}),"\n",(0,s.jsx)(e.h2,{id:"translation-cache-and-performance",children:"Translation Cache and Performance"}),"\n",(0,s.jsx)(e.h3,{id:"optimized-translation-caching",children:"Optimized Translation Caching"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from collections import OrderedDict\nimport hashlib\nimport time\n\nclass TranslationCache:\n    def __init__(self, max_size: int = 1000, ttl: int = 3600):\n        self.cache = OrderedDict()\n        self.max_size = max_size\n        self.ttl = ttl  # Time-to-live in seconds\n\n    def _generate_key(self, text: str, source_lang: str, target_lang: str, domain: str) -> str:\n        """Generate a cache key for the translation request"""\n        key_string = f"{text}_{source_lang}_{target_lang}_{domain}"\n        return hashlib.md5(key_string.encode()).hexdigest()\n\n    def get(self, text: str, source_lang: str, target_lang: str, domain: str) -> Optional[str]:\n        """Get cached translation"""\n        key = self._generate_key(text, source_lang, target_lang, domain)\n\n        if key in self.cache:\n            cached_result, timestamp = self.cache[key]\n\n            # Check if cache is still valid\n            if time.time() - timestamp < self.ttl:\n                # Move to end (LRU behavior)\n                del self.cache[key]\n                self.cache[key] = (cached_result, timestamp)\n                return cached_result\n            else:\n                # Remove expired entry\n                del self.cache[key]\n\n        return None\n\n    def put(self, text: str, source_lang: str, target_lang: str, domain: str, result: str):\n        """Put translation result in cache"""\n        key = self._generate_key(text, source_lang, target_lang, domain)\n\n        # Remove oldest entries if cache is full\n        while len(self.cache) >= self.max_size:\n            self.cache.popitem(last=False)\n\n        self.cache[key] = (result, time.time())\n\n    def invalidate(self, pattern: str = None):\n        """Invalidate cache entries based on pattern"""\n        if pattern is None:\n            self.cache.clear()\n        else:\n            # This would implement pattern-based invalidation\n            # For simplicity, clearing all in this example\n            self.cache.clear()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"content-translation-for-educational-materials",children:"Content Translation for Educational Materials"}),"\n",(0,s.jsx)(e.h3,{id:"translating-textbook-content",children:"Translating Textbook Content"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom enum import Enum\n\nclass TranslationStatus(Enum):\n    PENDING = "pending"\n    IN_PROGRESS = "in_progress"\n    COMPLETED = "completed"\n    FAILED = "failed"\n\n@dataclass\nclass TranslationJob:\n    id: str\n    content_id: str\n    source_lang: str\n    target_lang: str\n    content: str\n    status: TranslationStatus = TranslationStatus.PENDING\n    timestamp: float = None\n    translated_content: str = None\n    error_message: str = None\n\nclass ContentTranslationService:\n    def __init__(self, translation_engine: UrduTranslationEngine):\n        self.translation_engine = translation_engine\n        self.translation_cache = TranslationCache()\n        self.translation_jobs = {}\n        self.domain_specialized_terms = self._load_domain_terms()\n\n    def _load_domain_terms(self) -> Dict[str, Dict[str, str]]:\n        """Load domain-specific terminology"""\n        return {\n            "robotics": {\n                "physical ai": "\u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc",\n                "humanoid robotics": "\u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633",\n                "robot operating system": "\u0631\u0648\u0628\u0648\u0679 \u0622\u067e\u0631\u06cc\u0679\u0646\u06af \u0633\u0633\u0679\u0645",\n                "simulation": "\u0633\u0645\u0648\u0644\u06cc\u0634\u0646",\n                "gazebo": "\u06af\u0632\u06cc\u0628\u0648",\n                "unity": "\u06cc\u0648\u0646\u06cc\u0679\u06cc",\n                "nvidia isaac": "\u0627\u06cc\u0646 \u0648\u06cc\u0688\u06cc\u0627 \u0627\u06cc\u0633\u06cc\u06a9",\n                "vision-language-action": "\u0648\u0698\u0646-\u0632\u0628\u0627\u0646-\u06a9\u0627\u0631\u0631\u0648\u0627\u0626\u06cc",\n                "vla": "\u0648\u06cc \u0627\u06cc\u0644 \u0627\u06d2",\n                "reinforcement learning": "\u0631\u06cc \u0627\u06cc\u0646\u0641\u0627\u0631\u0633\u0645\u0646\u0679 \u0644\u0631\u0646\u0646\u06af",\n                "deep learning": "\u06af\u06c1\u0631\u0627\u0626 \u0644\u0631\u0646\u0646\u06af",\n                "computer vision": "\u06a9\u0645\u067e\u06cc\u0648\u0679\u0631 \u0648\u0698\u0646",\n                "natural language processing": "\u0646\u06cc\u0686\u0631\u0644 \u0644\u06cc\u0646\u06af\u0648\u06cc\u062c \u067e\u0631\u0648\u0633\u06cc\u0633\u0646\u06af",\n                "motion planning": "\u0645\u0648\u0634\u0646 \u067e\u0644\u0627\u0646\u0646\u06af",\n                "path planning": "\u067e\u0627\u062a\u06be \u067e\u0644\u0627\u0646\u0646\u06af",\n                "collision detection": "\u06a9\u0648\u0644\u06cc\u0698\u0646 \u0688\u06cc\u0679\u06cc\u06a9\u0634\u0646",\n                "inverse kinematics": "\u0627\u0646 \u0648\u0631\u0633 \u06a9\u0646\u06cc\u0645\u06cc\u0679\u06a9\u0633",\n                "forward kinematics": "\u0641\u0627\u0631\u0648\u0631\u0688 \u06a9\u0646\u06cc\u0645\u06cc\u0679\u06a9\u0633",\n                "control systems": "\u06a9\u0646\u0679\u0631\u0648\u0644 \u0633\u0633\u0679\u0645",\n                "sensors and actuators": "\u0633\u06cc\u0646\u0633\u0631\u0632 \u0627\u0648\u0631 \u0627\u06cc\u06a9\u0686\u0648 \u0627\u06cc\u0679\u0631\u0632",\n                "feedback control": "\u0641\u0631\u06cc\u0642\u06cc\u06a9 \u0628\u06cc\u06a9 \u06a9\u0646\u0679\u0631\u0648\u0644"\n            }\n        }\n\n    def translate_content(self,\n                         content_id: str,\n                         text: str,\n                         target_lang: str = \'ur\',\n                         domain: str = \'robotics\') -> str:\n        """Translate educational content with caching"""\n        # Check cache first\n        cached_result = self.translation_cache.get(\n            text=text,\n            source_lang=\'en\',\n            target_lang=target_lang,\n            domain=domain\n        )\n\n        if cached_result:\n            return cached_result\n\n        # Apply domain-specific terminology\n        processed_text = self._apply_domain_terms(text, domain)\n\n        # Perform translation\n        translated_text = self.translation_engine.translate_urdu(\n            processed_text,\n            source_lang=\'en\'\n        )\n\n        # Store in cache\n        self.translation_cache.put(\n            text=text,\n            source_lang=\'en\',\n            target_lang=target_lang,\n            domain=domain,\n            result=translated_text\n        )\n\n        return translated_text\n\n    def _apply_domain_terms(self, text: str, domain: str) -> str:\n        """Apply domain-specific terminology to text"""\n        if domain not in self.domain_specialized_terms:\n            return text\n\n        domain_terms = self.domain_specialized_terms[domain]\n        processed_text = text\n\n        # Replace technical terms (case-insensitive)\n        for english_term, urdu_term in domain_terms.items():\n            processed_text = processed_text.replace(\n                english_term.lower(),\n                f"[{urdu_term} - {english_term}]"\n            )\n            processed_text = processed_text.replace(\n                english_term.capitalize(),\n                f"[{urdu_term} - {english_term}]"\n            )\n\n        return processed_text\n\n    def translate_document(self,\n                          document: Dict[str, str],\n                          target_lang: str = \'ur\',\n                          domain: str = \'robotics\') -> Dict[str, str]:\n        """Translate an entire document with structure preserved"""\n        translated_doc = {}\n\n        for section, content in document.items():\n            if isinstance(content, str):\n                translated_doc[section] = self.translate_content(\n                    content_id=section,\n                    text=content,\n                    target_lang=target_lang,\n                    domain=domain\n                )\n            elif isinstance(content, dict):\n                # Recursively translate nested content\n                translated_doc[section] = self.translate_document(\n                    content,\n                    target_lang,\n                    domain\n                )\n            else:\n                translated_doc[section] = content\n\n        return translated_doc\n'})}),"\n",(0,s.jsx)(e.h2,{id:"real-time-translation-for-chatbots",children:"Real-Time Translation for Chatbots"}),"\n",(0,s.jsx)(e.h3,{id:"integration-with-ai-chatbot-for-urdu-support",children:"Integration with AI Chatbot for Urdu Support"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class MultilingualChatbot:\n    def __init__(self, translation_service: ContentTranslationService,\n                 base_chatbot):\n        self.translation_service = translation_service\n        self.base_chatbot = base_chatbot\n        self.active_language = \'en\'  # Default language\n\n    def process_message(self, message: str, user_language: str = \'en\') -> str:\n        """Process message with language support"""\n        # Set active language\n        self.active_language = user_language\n\n        # If user is speaking in Urdu, translate to English for processing\n        if user_language == \'ur\':\n            english_message = self.translation_service.translation_engine.translate_urdu(\n                message,\n                source_lang=\'ur\'\n            )\n            response = self.base_chatbot.process(english_message)\n        else:\n            response = self.base_chatbot.process(message)\n\n        # Translate response back to user\'s language if needed\n        if self.active_language != \'en\':\n            # Translate the response back to the user\'s language\n            user_response = self.translation_service.translation_engine.translate_urdu(\n                response,\n                source_lang=\'en\'\n            )\n            return user_response\n        else:\n            return response\n\n    def toggle_language(self, target_lang: str) -> str:\n        """Toggle between languages"""\n        if target_lang == self.active_language:\n            return f"Already using {target_lang}"\n\n        self.active_language = target_lang\n        welcome_msg = {\n            \'ur\': "\u062e\u0648\u0634 \u0622\u0645\u062f\u06cc\u062f! \u0622\u067e \u0627\u0628 \u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u0686\u06cc\u0679 \u06a9\u0631 \u0633\u06a9\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4",\n            \'en\': "Welcome! You can now chat in English.",\n            \'hi\': "\u0938\u094d\u0935\u093e\u0917\u0924 \u0939\u0948! \u0905\u092c \u0906\u092a \u0939\u093f\u0902\u0926\u0940 \u092e\u0947\u0902 \u091a\u0948\u091f \u0915\u0930 \u0938\u0915\u0924\u0947 \u0939\u0948\u0902\u0964"\n        }\n\n        if target_lang in welcome_msg:\n            return self._translate_if_needed(welcome_msg[target_lang], target_lang)\n\n        return f"Language switched to {target_lang}"\n\n    def _translate_if_needed(self, text: str, target_lang: str) -> str:\n        """Translate text if the target language is different from English"""\n        if target_lang == \'en\':\n            return text\n        else:\n            return self.translation_service.translation_engine.translate_urdu(\n                text,\n                source_lang=\'en\' if target_lang != \'en\' else target_lang\n            )\n'})}),"\n",(0,s.jsx)(e.h2,{id:"translation-quality-and-evaluation",children:"Translation Quality and Evaluation"}),"\n",(0,s.jsx)(e.h3,{id:"quality-assessment-framework",children:"Quality Assessment Framework"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom sklearn.metrics import accuracy_score\nimport sacrebleu\n\nclass TranslationQualityEvaluator:\n    def __init__(self):\n        self.translation_quality_scores = {}\n        self.bleu_scores = {}\n\n    def evaluate_translation_quality(self,\n                                   original_text: str,\n                                   translated_text: str,\n                                   reference_translation: str = None) -> Dict[str, float]:\n        \"\"\"Evaluate quality of translation\"\"\"\n        metrics = {}\n\n        # If reference translation is provided, calculate BLEU score\n        if reference_translation:\n            try:\n                bleu_score = sacrebleu.sentence_bleu(\n                    hypothesis=translated_text,\n                    references=[reference_translation]\n                )\n                metrics['bleu_score'] = bleu_score.score\n            except:\n                metrics['bleu_score'] = 0.0\n\n        # Calculate character-level similarity (simple metric)\n        similarity = self._calculate_similarity(original_text, translated_text)\n        metrics['character_similarity'] = similarity\n\n        # Language detection accuracy\n        try:\n            import langdetect\n            detected_lang = langdetect.detect(translated_text)\n            metrics['correct_language'] = 1.0 if detected_lang.startswith('ur') else 0.0\n        except:\n            metrics['correct_language'] = 0.5  # Neutral score if detection fails\n\n        return metrics\n\n    def _calculate_similarity(self, text1: str, text2: str) -> float:\n        \"\"\"Calculate similarity between two texts\"\"\"\n        # Simple character-based similarity\n        set1 = set(text1.lower())\n        set2 = set(text2.lower())\n\n        intersection = len(set1.intersection(set2))\n        union = len(set1.union(set2))\n\n        return intersection / union if union > 0 else 0.0\n\n    def evaluate_batch_translations(self,\n                                  original_texts: List[str],\n                                  translated_texts: List[str],\n                                  reference_texts: List[str] = None) -> Dict[str, float]:\n        \"\"\"Evaluate a batch of translations\"\"\"\n        all_metrics = {\n            'bleu_scores': [],\n            'character_similarities': [],\n            'language_accuracy': []\n        }\n\n        for i, (orig, trans) in enumerate(zip(original_texts, translated_texts)):\n            ref = reference_texts[i] if reference_texts else None\n            metrics = self.evaluate_translation_quality(orig, trans, ref)\n\n            all_metrics['bleu_scores'].append(metrics.get('bleu_score', 0.0))\n            all_metrics['character_similarities'].append(metrics.get('character_similarity', 0.0))\n            all_metrics['language_accuracy'].append(metrics.get('correct_language', 0.5))\n\n        # Calculate averages\n        avg_metrics = {\n            'avg_bleu_score': np.mean(all_metrics['bleu_scores']),\n            'avg_character_similarity': np.mean(all_metrics['character_similarities']),\n            'avg_language_accuracy': np.mean(all_metrics['language_accuracy']),\n        }\n\n        return avg_metrics\n"})}),"\n",(0,s.jsx)(e.h2,{id:"ros-2-integration-for-translation-services",children:"ROS 2 Integration for Translation Services"}),"\n",(0,s.jsx)(e.h3,{id:"translation-service-node",children:"Translation Service Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom ai_msgs.srv import TranslateText\nfrom ai_msgs.msg import TranslationResult\n\nclass TranslationNode(Node):\n    def __init__(self):\n        super().__init__(\'translation_node\')\n\n        # Service for text translation\n        self.translation_service = self.create_service(\n            TranslateText, \'translate_text\', self.translate_text_callback\n        )\n\n        # Publisher for translation results\n        self.result_publisher = self.create_publisher(\n            TranslationResult, \'translation_result\', 10\n        )\n\n        # Initialize translation components\n        self.urdu_engine = UrduTranslationEngine()\n        self.translation_service_impl = ContentTranslationService(self.urdu_engine)\n        self.quality_evaluator = TranslationQualityEvaluator()\n\n    def translate_text_callback(self, request, response):\n        """Callback for translation service"""\n        try:\n            # Perform translation\n            translated_text = self.translation_service_impl.translate_content(\n                content_id="service_request",\n                text=request.text,\n                target_lang=request.target_language,\n                domain=request.domain\n            )\n\n            # Evaluate quality (if reference provided)\n            if request.reference_translation:\n                quality_metrics = self.quality_evaluator.evaluate_translation_quality(\n                    original_text=request.text,\n                    translated_text=translated_text,\n                    reference_translation=request.reference_translation\n                )\n\n                response.quality_score = quality_metrics.get(\'bleu_score\', 0.0)\n\n            # Set response\n            response.translated_text = translated_text\n            response.success = True\n\n            # Publish result for other nodes to use\n            result_msg = TranslationResult()\n            result_msg.original_text = request.text\n            result_msg.translated_text = translated_text\n            result_msg.source_language = request.source_language\n            result_msg.target_language = request.target_language\n            result_msg.timestamp = self.get_clock().now().to_msg()\n\n            self.result_publisher.publish(result_msg)\n\n        except Exception as e:\n            self.get_logger().error(f"Translation error: {e}")\n            response.success = False\n            response.error_message = str(e)\n\n        return response\n'})}),"\n",(0,s.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(e.h3,{id:"async-translation-processing",children:"Async Translation Processing"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass AsyncTranslationProcessor:\n    def __init__(self, translation_engine, max_workers=4):\n        self.translation_engine = translation_engine\n        self.executor = ThreadPoolExecutor(max_workers=max_workers)\n\n    async def translate_batch_async(self,\n                                   texts: List[str],\n                                   source_lang: str = \'en\',\n                                   target_lang: str = \'ur\') -> List[str]:\n        """Asynchronously translate a batch of texts"""\n        loop = asyncio.get_event_loop()\n\n        tasks = [\n            loop.run_in_executor(\n                self.executor,\n                self.translation_engine.translate_urdu,\n                text,\n                source_lang\n            )\n            for text in texts\n        ]\n\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Handle any exceptions in results\n        processed_results = []\n        for result in results:\n            if isinstance(result, Exception):\n                processed_results.append(f"[ERROR: {str(result)}]")\n            else:\n                processed_results.append(result)\n\n        return processed_results\n\n    async def translate_stream(self,\n                              text_stream: List[str],\n                              source_lang: str = \'en\',\n                              target_lang: str = \'ur\') -> List[str]:\n        """Translate a stream of texts with batching for performance"""\n        batch_size = 10\n        all_results = []\n\n        for i in range(0, len(text_stream), batch_size):\n            batch = text_stream[i:i + batch_size]\n            batch_results = await self.translate_batch_async(\n                batch, source_lang, target_lang\n            )\n            all_results.extend(batch_results)\n\n        return all_results\n'})}),"\n",(0,s.jsx)(e.p,{children:"This implementation provides a comprehensive framework for AI translation in Physical AI and Humanoid Robotics applications, with special focus on Urdu support for Panaversity users. The system includes caching, quality evaluation, real-time processing, and ROS 2 integration capabilities."})]})}function d(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(u,{...n})}):u(n)}},8453(n,e,t){t.d(e,{R:()=>i,x:()=>l});var a=t(6540);const s={},r=a.createContext(s);function i(n){const e=a.useContext(r);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);