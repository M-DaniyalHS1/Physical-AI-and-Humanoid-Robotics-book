"use strict";(globalThis.webpackChunkai_textbook_frontend=globalThis.webpackChunkai_textbook_frontend||[]).push([[984],{3800(i){i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/intro","label":"Introduction","docId":"intro","unlisted":false},{"type":"category","label":"ROS 2","items":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ros2/intro","label":"Introduction to ROS 2","docId":"ros2/intro","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ros2/installation","label":"ROS 2 Installation","docId":"ros2/installation","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ros2/basics","label":"ROS 2 Basics","docId":"ros2/basics","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Gazebo & Unity","items":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/gazebo-unity/intro","label":"Gazebo & Unity Simulation","docId":"gazebo-unity/intro","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/gazebo-unity/simulation","label":"Simulation Setup and Configuration","docId":"gazebo-unity/simulation","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/gazebo-unity/integration","label":"Simulation Integration with ROS 2","docId":"gazebo-unity/integration","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"NVIDIA Isaac","items":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/nvidia-isaac/intro","label":"Introduction to NVIDIA Isaac","docId":"nvidia-isaac/intro","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/nvidia-isaac/setup","label":"NVIDIA Isaac Setup","docId":"nvidia-isaac/setup","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/nvidia-isaac/examples","label":"NVIDIA Isaac Examples","docId":"nvidia-isaac/examples","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"VLA (Vision-Language-Action)","items":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/vla/intro","label":"Introduction to VLA (Vision-Language-Action)","docId":"vla/intro","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/vla/models","label":"VLA Models and Architectures","docId":"vla/models","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/vla/applications","label":"VLA Applications in Physical AI","docId":"vla/applications","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"AI Integration","items":[{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ai/chatbot","label":"AI Chatbot Integration","docId":"ai/chatbot","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ai/personalization","label":"AI Personalization","docId":"ai/personalization","unlisted":false},{"type":"link","href":"/Physical-AI-and-Humanoid-Robotics-book/ur/docs/ai/translation","label":"AI Translation","docId":"ai/translation","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"ai/chatbot":{"id":"ai/chatbot","title":"AI Chatbot Integration","description":"This section covers the integration of AI chatbots with Physical AI and Humanoid Robotics systems, enabling natural language interaction with robotic platforms.","sidebar":"tutorialSidebar"},"ai/personalization":{"id":"ai/personalization","title":"AI Personalization","description":"Personalization in AI-powered robotics systems enables customization of robot behavior, interaction style, and capabilities based on individual user preferences, background, and context. This section covers how to implement personalization in Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"ai/translation":{"id":"ai/translation","title":"AI Translation","description":"This section covers AI-powered translation capabilities for Physical AI and Humanoid Robotics applications, with a focus on supporting the local language (Urdu) for Panaversity users. Translation enables broader access to educational content and enhances human-robot interaction in multilingual environments.","sidebar":"tutorialSidebar"},"gazebo-unity/integration":{"id":"gazebo-unity/integration","title":"Simulation Integration with ROS 2","description":"This section covers how to integrate simulation environments with ROS 2 for Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"gazebo-unity/intro":{"id":"gazebo-unity/intro","title":"Gazebo & Unity Simulation","description":"Simulation is a critical component in developing Physical AI and Humanoid Robotics systems. It allows for safe, rapid testing of algorithms without the risk of hardware damage. This section covers both Gazebo and Unity as simulation environments.","sidebar":"tutorialSidebar"},"gazebo-unity/simulation":{"id":"gazebo-unity/simulation","title":"Simulation Setup and Configuration","description":"This guide provides instructions for setting up simulation environments for Physical AI and Humanoid Robotics applications using both Gazebo and Unity.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"Welcome to the AI-Powered Physical AI & Humanoid Robotics Textbook, an interactive learning platform that bridges the gap between digital AI and physical robots.","sidebar":"tutorialSidebar"},"nvidia-isaac/examples":{"id":"nvidia-isaac/examples","title":"NVIDIA Isaac Examples","description":"This section provides practical examples of using NVIDIA Isaac for Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"nvidia-isaac/intro":{"id":"nvidia-isaac/intro","title":"Introduction to NVIDIA Isaac","description":"NVIDIA Isaac is NVIDIA\'s comprehensive platform for developing, simulating, and deploying AI-powered robotics applications. It provides a complete solution for building intelligent robots that can perceive, understand, and interact with the physical world.","sidebar":"tutorialSidebar"},"nvidia-isaac/setup":{"id":"nvidia-isaac/setup","title":"NVIDIA Isaac Setup","description":"This guide will walk you through setting up NVIDIA Isaac for Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"ros2/basics":{"id":"ros2/basics","title":"ROS 2 Basics","description":"In this section, we\'ll cover fundamental ROS 2 concepts that are essential for Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"ros2/installation":{"id":"ros2/installation","title":"ROS 2 Installation","description":"This guide will walk you through the installation process for ROS 2, focusing on configurations relevant to Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"},"ros2/intro":{"id":"ros2/intro","title":"Introduction to ROS 2","description":"Robot Operating System 2 (ROS 2) is a set of software libraries and tools that help you build robot software. It is the successor to ROS (Robot Operating System), offering improved architecture, security, and real-time capabilities.","sidebar":"tutorialSidebar"},"vla/applications":{"id":"vla/applications","title":"VLA Applications in Physical AI","description":"This section explores practical applications of Vision-Language-Action (VLA) systems in Physical AI and Humanoid Robotics, including implementation examples and real-world use cases.","sidebar":"tutorialSidebar"},"vla/intro":{"id":"vla/intro","title":"Introduction to VLA (Vision-Language-Action)","description":"Vision-Language-Action (VLA) represents an emerging paradigm in AI where vision, language, and action are tightly integrated, enabling robots to understand and execute complex tasks described in natural language while perceiving and interacting with the physical world.","sidebar":"tutorialSidebar"},"vla/models":{"id":"vla/models","title":"VLA Models and Architectures","description":"This section covers the various models and architectures used in Vision-Language-Action (VLA) systems for Physical AI and Humanoid Robotics applications.","sidebar":"tutorialSidebar"}}}}')}}]);